<!DOCTYPE html>
<html>

  <head>
      <script async src="https://www.googletagmanager.com/gtag/js?id=UA-116924853-1"></script>
      <script>
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());

          gtag('config', 'UA-116924853-1');
          </script>
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1">

<title>Sareer Ul Amin</title>
<meta name="description" content="">

<link rel="stylesheet" href="css/main.css">
<link rel="stylesheet" href="https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css"/>
<link rel="shortcut icon" type="image/ico" href="favicon.ico" />		

    <!-- Custom fonts for this template -->
    <link href="https://fonts.googleapis.com/css?family=Saira+Extra+Condensed:100,200,300,400,500,600,700,800,900" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,600,600i,700,700i,800,800i" rel="stylesheet">
    <link href="vendor/font-awesome/css/font-awesome.min.css" rel="stylesheet">
    <link href="vendor/devicons/css/devicons.min.css" rel="stylesheet">
    <link href="vendor/simple-line-icons/css/simple-line-icons.css" rel="stylesheet">
	

<link rel='stylesheet' id='open-sans-css'  href='//fonts.googleapis.com/css?family=Open+Sans%3A300italic%2C400italic%2C600italic%2C300%2C400%2C600&#038;subset=latin%2Clatin-ext&#038;ver=4.2.4' type='text/css' media='all' />
<link href='https://fonts.googleapis.com/css?family=Titillium+Web:600italic,600,400,400italic' rel='stylesheet' type='text/css'>

<!-- fontawesome and academicons -->
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.1.0/css/all.css" integrity="sha384-lKuwvrZot6UHsBSfcMvOkWwlCMgc0TaWr+30HWe3a4ltaBwTZhyTEggF5tJv8tbt" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css">




</head>


  <body>

    <header class="site-header">

  <div class="wrapper">

    <a class="site-title" href="/">Sareer Ul Amin</a>


    <nav class="site-nav">

      <a href="#" class="menu-icon menu.open">
        <svg viewBox="0 0 18 15">
          <path fill="#4CAC9D" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
          <path fill="#4CAC9D" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
          <path fill="#4CAC9D" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
        </svg>
      </a>  

    <div class="trigger"><h1>Main Navigation</h1>

 <ul class="menu">

    
    
    
    </ul>


     </div>  
    </nav>

  </div>

</header>


    <div class="page-content">
      <div class="wrapper">
        <p><img src="img/amin.jpg" style="width: 180px; float: right" hspace="20" /></p>

        <p>I received a bachelor's degree in computer science from Islamia College, Peshawar, Pakistan, advised by <a href="https://scholar.google.com/citations?user=E4-dElIAAAAJ&hl=en">Prof. Mohammad Sajjad</a>. Currently, I am working as a research assistant at the Graphic Realization Lab <a href="http://grlab.cau.ac.kr/">(GR Lab)</a>. My research interests include video analysis, medical image analysis, image segmentation, object detection, image processing, computer vision, machine learning, and deep learning. Feel free to contact me if you are interested in research collaborations in the relevant areas.</p>

<!-- Icons from fontawesome (Make less ugly later) -->
<ul class="list-inline list-social-icons mb-0">

              <li class="list-inline-item">
                  <a href="https://scholar.google.com/citations?user=uxndv_oAAAAJ&hl=en&oi=ao">
                      <span class="fa-stack fa-lg">
                          <i class="ai ai-google-scholar-square ai-2x"></i>
                      </span>
                  </a>
              </li>

              <li class="list-inline-item">
                  <a href="https://github.com/sareerulamin">
                      <span class="fa-stack fa-lg">
                          <i class="fa fa-square fa-stack-2x"></i>
                          <i class="fab fa-github fa-stack-1x fa-inverse"></i>
                      </span>
                  </a>
              </li>

              <li class="list-inline-item">
                  <a href="https://twitter.com/sareerulamin320">
                      <span class="fa-stack fa-lg">
                          <i class="fa fa-square fa-stack-2x"></i>
                          <i class="fab fa-twitter fa-stack-1x fa-inverse"></i>
                      </span>
                  </a>
              </li>
	       <li class="list-inline-item">
                  <a href="https://www.linkedin.com/in/sareer-ulamin-9a5171186/">
                      <span class="fa-stack fa-lg">
                          <i class="fa fa-square fa-stack-2x"></i>
			  <i class="fab fa-linkedin fa-stack-1x fa-inverse"></i>   
                      </span>
                  </a>
              </li>

              <li class="list-inline-item">
                  <a href="amin_cv.pdf">
                      <span class="fa-stack fa-lg">
                          <i class="fa fa-square fa-stack-2x"></i>
                          <i class="fa fa-id-card fa-stack-1x fa-inverse"></i>
                      </span>
                  </a>
              </li>
</ul>
<p><strong>Contact</strong>: sareerulamin320@ *at* gmail.com<br />
<h1 id="news--activities">News &amp; Activities</h1>
<hr />

<div class="container"> <div class="events">
    <ul>
        <li> Novemeber 2023: Happy to be a <a href="https://neurips.cc/Conferences/2023/ProgramCommittee#top-reviewers">top reviewer</a> for NeurIPS 2023.
        <li> October 2023: I'm hiring for <a href="https://www.universiteitleiden.nl/en/vacancies/2023/qw4/23-683141412-phd-candidates-detailed-video-understanding">two PhD positions in 'Detailed Video Understanding'</a>
        <li> September 2023: Two papers accepted to NeurIPS
        <li> September 2023: I joined Leiden University as an Assistant Professor
        <li> August 2023: I'm thrilled to receive a <a href="https://www.nwo.nl/en/researchprogrammes/nwo-talent-programme/projects-veni/veni-2022">Veni</a> grant for my project "From What to How: Perceiving Subtle Details in Videos"
        <li> July 2023: Our paper "Tubelet-Contrastive Self-Supervision for Video-Efficient Generalization" was accepted to ICCV, <a href="https://arxiv.org/abs/2303.11003">pre-print available here</a>
        <li> July 2023: In September I'll join Leiden University as an Assistant Professor, look out for PhD openings!
        <li> June 2023: I gave a talk at the CVPR 2023 workshop on <a href="https://sites.google.com/view/l3d-ivu-2023"> Learning with Limited Labelled Data for Image and Video Understanding</a>
        <li> April 2023: I became an associate editor of CVIU
        <li> February 2023: I gave a talk at the Rising Stars in AI Symposium 2023 in KAUST
        <li> December 2022: Excited to be a Workshop Chair for BMVC 2023
        <li> December 2022: I'm honored to serve as an Area Chair for ICCV 2023
        <li> December 2022: I gave a guest lecture at the University of Catania
            <li> October 2022: Happy to be an <a href="https://eccv2022.ecva.net/program/outstanding-reviewers/">outstanding reviewer for ECCV 2022</a>
        <li> September 2022: I became an <a href="https://ellis.eu/">ELLIS</a> member
        <li> September 2022: I gave a talk at the <a href="https://sites.google.com/view/videosymposium2022/homepage">2022 Video Understanding Symposium</a>
        <li> July 2022: <a href="https://arxiv.org/abs/2203.14221">'How Severe is Benchmark-Sensitivity in Video Self-Supervised Learning?'</a> is accepted to ECCV
        <li> June 2022: I was a panelist at Women in Computer Vision CVPR 2022
        <li> May 2022: I gave a talk at the <a href="http://computervisionbylearning.info/">Computer Vision by Learning Summer School</a>
        <li> March 2022: Our papers on <a href="https://hazeldoughty.github.io/Papers/PseudoAdverbs">Pseudo Adverbs</a> and <a href="https://xiaobai1217.github.io/DomainAdaptation" >Audio-Adaptive Action Recognition</a> are accepted to CVPR.</li>
        <li> September 2021: Our paper <a href="https://arxiv.org/abs/2006.13256">Rescaling Egocentric Vision</a> is accepted for publication in IJCV
        <li> September 2021: I'm an <a href="http://iccv2021.thecvf.com/outstanding-reviewers">Outstanding Reviewer for ICCV 2021</a>
        <li> August 2021: Our paper <a href="https://arxiv.org/abs/2108.03656">Skeleton-Contrastive 3D Action Representation Learning</a> was accepted at ACM Multimedia 2021
        <li> July 2021: I'm co-organizing the <a href="http://preregister.science">NeurIPS'21 Workshop on Pre-registration in ML</a>
        <li> May 2021: Happy to be an <a href="http://cvpr2021.thecvf.com/node/184">outstanding reviewer</a> for CVPR 2021
        <li> April 2021: I'm co-organizing the <a href="https://sites.google.com/view/srvu-iccv21-workshop">Workshop on Structured Representations for Video Understanding</a> at ICCV.
        <li> March 2021: Our paper <a href="https://arxiv.org/abs/2103.10095">On Semantic Similarity in Video Retrieval</a> got accepted at CVPR 2021.
        <li> February 2021: I gave a <a href="https://www.youtube.com/watch?v=0Tz-4_c3A-E&ab_channel=AIinRoboticsSeminarSeries">talk</a> at the <a href="https://www.pair.toronto.edu/robotics-rg/">University of Toronto's AI in Robotics Seminar Series</a>.
        <li>October 2020: Successfully defended my PhD thesis "Skill Determination from Long Videos". Thank you to my examiners Josef Sivic and Bill Freeman.
		<li> August 2020: Proud to be an <a href="https://eccv2020.eu/outstanding-reviewers/"> Outstanding Reviewer for ECCV 2020</a>
		<li> July 2020: <a href="https://epic-kitchens.github.io/2020-100">EPIC-Kitchens-100</a> released. This is an extension of the original EPIC-Kitchens, now up 100 hours of video and 90,000 action segments.
		<li> June 2020: I presented our CVPR paper Action Modifers: Learning from Adverbs in Instructional Videos at the <a href="https://www.robots.ox.ac.uk/~vgg/challenges/video-pentathlon/">Video Pentathlon workshop</a>.
		<li> April 2020: The journal paper EPIC-KITCHENS Dataset: Collection Challenges and Baselines has been accepted to IEEE Transactions on Pattern Analysis and Machine Intelligence
		<li> Feb 2020: <a href="https://arxiv.org/abs/1912.06617">Action Modifers: Learning from Adverbs in Instructional Videos</a> is accepted in CVPR 2020.</li>
        <li> Jan 2020: I'm co-organizing the <a href="https://sites.google.com/view/wicvworkshop-cvpr2020/">Women in Computer Vision</a> and <a href="https://eyewear-computing.org/EPIC_CVPR20/">Egocentric Perception, Interaction and Computing</a> workshops at CVPR 2020.</li>
        <li> Dec 2019: Our new paper on 'Action Modifiers' is available on <a href="https://arxiv.org/abs/1912.06617">arXiv</a></li>
        <li> June 2019: We're presenting our paper on rank-aware temporal attention for skill determination at CVPR 2019.
    </ul>
  </div></div>
<h1 id="publications">Publications</h1>
<hr />

<table class="researchtable">

    <tbody>
	    
	<tr>
            <td class="img"> <img src="img/6.png" /> </td>
            <td valign="top">
                <strong>Deep learning based active learning technique for data annotation and improve the overall performance of classification models</strong><br />
                <u>SAREER UL AMiN</u>, Adnan Hussain, Bumsoo Kim, Sanghyun Seo*<br />
                <strong>Expert Systems with Applications</strong>, 2023. <br />
		<strong>[IF : 8.66, Rank Q1]</strong><br />
                <strong> <a href="https://doi.org/10.1016/j.eswa.2023.120391">[Link]</a> </strong>
            </td>
        </tr>
	    
        <tr>
            <td class="img"> <img src="img/1.png" /> </td>
            <td valign="top">
                <strong>Video Anomaly Detection Utilizing Efficient Spatiotemporal Feature Fusion with 3D Convolutions and LSTM Modules</strong><br />
                <u>SAREER UL AMiN</u>, BUMSOO KiM, YONGHOON JUNG, SANGHYUN SEO, AND SANGOH PARK*<br />
                <strong>Advanced Intelligent Systems</strong>, 2023. <br />
		<strong>[IF : 7.4, Rank Q1]</strong><br />
                <strong> <a href="https://www.sciencedirect.com/science/article/pii/S095741742300893X">[Link]</a> </strong>
            </td>
        </tr>

	<tr>
            <td class="img"> <img src="img/8.png" /> </td>
            <td valign="top">
                <strong>An automated chest X-ray analysis for COVID-19, tuberculosis, and pneumonia employing ensemble learning approach</strong><br />
                <u>SAREER UL AMiN</u>, Sher Taj, Adnan Hussain, Sanghyun Seo*<br />
                <strong>Biomedical Signal Processing and Control</strong>, 2023. <br />
		<strong>[IF : 5.1, Rank Q1]</strong><br />
                <strong> <a href="https://doi.org/10.1016/j.bspc.2023.105408">[Link]</a> </strong>
            </td>
        </tr>

	<tr>
            <td class="img"> <img src="img/3.png" /> </td>
            <td valign="top">
                <strong>An Efficient Attention-Based Strategy for Anomaly Detection in Surveillance Video</strong><br />
                <u>SAREER UL AMiN</u>, Yongjun Kim, Irfan Sami, Sangoh Park, Sanghyun Seo*<br />
                <strong>Computer Systems Science and Engineering</strong>, 2023. <br />
		<strong>[IF : 4.397, Rank Q1]</strong><br />
                <strong> <a href="https://doi.org/10.32604/csse.2023.034805">[Link]</a> </strong>
            </td>
        </tr> 

	<tr>
            <td class="img"> <img src="img/7.png" /> </td>
            <td valign="top">
                <strong>An Automated Chest X-Ray Image Analysis for Covid-19 and Pneumonia Diagnosis using Deep Ensemble Strategy</strong><br />
                <u>SAREER UL AMiN</u>, Adnan Hussain, Hunjoo Lee, Asma Khan, Noreen Fayyaz Khan, Sanghyun Seo*<br />
                <strong>IEEE Access</strong>, 2023. <br />
		<strong>[IF : 3.9, Rank Q2]</strong><br />
                <strong> <a href="https://doi.org/10.1109/ACCESS.2023.3312533">[Link]</a> </strong>
            </td>
        </tr>

	<tr>
            <td class="img"> <img src="img/2.png" /> </td>
            <td valign="top">
                <strong>EADN: An Efficient Deep Learning Model for Anomaly Detection in Videos</strong><br />
                <u>SAREER UL AMiN</u>, Mohib Ullah, Muhammad Sajjad*, Faouzi Alaya Cheikh, Mohammad Hijji, Abdulrahman Hijji, Khan Muhammad*<br />
                <strong>Mathematics</strong>, 2022. <br />
		<strong>[IF : 2.592, Rank Q1]</strong><br />
                <strong> <a href="https://doi.org/10.3390/math10091555">[Link]</a> </strong>
            </td>
        </tr>

	

	 <tr>
            <td class="img"> <img src="img/4.png" /> </td>
            <td valign="top">
                <strong>Serious games in science education. A systematic literature review</strong><br />
                Mohib Ullah*, <u>SAREER UL AMiN</u>, Muhammad Munsif, Utkurbek Safaev, Habib Khan, Salman Khan, Habib Ullah<br />
                <strong>Virtual Reality & Intelligent Hardware </strong>, 2022. <br />
                <strong> <a href="https://doi.org/10.1016/j.vrih.2022.02.001">[Link]</a> </strong>
            </td>
        </tr>   

	<tr>
            <td class="img"> <img src="img/5.png" /> </td>
            <td valign="top">
                <strong>Convergence Enhancement of Super-Twisting Sliding Mode Control Using Artificial Neural Network for DFIG-Based Wind Energy Conversion Systems</strong><br />
                Irfan Sami, Shafaat Ullah, <u>SAREER UL AMiN</u>, Ahmed Al-Durra, Nasim Ullah, Jong-Suk Ro*<br />
                <strong>IEEE Access </strong>, 2022. <br />
		<strong>[IF : 3.9, Rank Q2]</strong><br />
                <strong> <a href="https://doi.org/10.1109/ACCESS.2022.3205632">[Link]</a> </strong>
            </td>
        </tr>   
	

	<tr>
            <td class="img"> <img src="img/9.png" /> </td>
            <td valign="top">
                <strong>An Efficient and Robust Hand Gesture Recognition System of Sign Language Employing Finetuned Inception-V3 and Efficientnet-B0 Network</strong><br />
                Adnan Hussain, <u>SAREER UL AMiN</u>, Muhammad Fayaz, Sanghyun Seo*<br />
                <strong>Computer Systems Science and Engineering</strong>, 2023. <br />
		<strong>[IF : 4.397, Rank Q1]</strong><br />
                <strong> <a href="http://dx.doi.org/10.32604/csse.2023.037258">[Link]</a> </strong>
            </td>
        </tr>

	<tr>
            <td class="img"> <img src="img/10.png" /> </td>
            <td valign="top">
                <strong>Minecraft-ify: Minecraft Style Image Generation with Text-guided Image Editing for In-Game Application</strong><br />
                Bumsoo Kim, Sanghyun Byun, Yonghoon Jung, Wonseop Shin, <u>SAREER UL AMiN</u>, Sanghyun Seo*<br />
                <strong>NeurIPS 2023 Workshop on Machine Learning for Creativity and Design</strong>, 2023. <br />
                <strong> <a href="https://gh-bumsookim.github.io/Minecraft-ify/">[Link]</a> </strong>
            </td>
        </tr>

</tbody>
</table>
<br>
<h1 id="people" style="padding-top: 10px">Collaborator</h1>
<hr />
<br>
<ul>
    <li>2022-present - <a href="https://scholar.google.com/citations?user=_pZUwQoAAAAJ&hl=en&oi=ao">Asim Niaz</a> (PhD student from Chung-Ang University, South Korea)
    <li>2021-present - <a href="https://scholar.google.com/citations?user=E4-dElIAAAAJ&hl=en">Prof Mohammad Sajjad</a> </li>
    <li>2018-2021 - <a href="https://scholar.google.com/citations?user=k5oUZyQAAAAJ&hl=en">Khan Mohammad</a></li>
    <li> 2018-2022 - <a href="https://scholar.google.com/citations?user=YJ5X6HYAAAAJ&hl=en">Mohammad Munsif</a> (PhD student from Sejong University, South Korea)</li>
    <li>2018-2021 - <a href="https://scholar.google.com/citations?user=3wZrDLsAAAAJ&hl=en">Habib Khan</a> (MS student from Sejong University, South Korea)</li>
</ul>

<br>
<h1 id="misc" style="padding-top: 10px">Academic Service</h1>
<hr />
<br>
Organizer: Workshop Chair for BMVC 2023, <a href="https://sites.google.com/view/nccv-2022">Netherlands Conference on Computer Vision</a>, <a href="http://preregister.science">NeurIPS'21 Workshop on Pre-registration in ML</a>, <a href="https://sites.google.com/view/srvu-iccv21-workshop">ICCV'21 Workshop on Structured Representations for Video Understanding</a>, <a href="https://sites.google.com/view/wicvworkshop-cvpr2020/">WiCV@CVPR2020</a>, <a href="https://eyewear-computing.org/EPIC_CVPR20/">EPIC@CVPR2020</a>, <a href="https://eyewear-computing.org/EPIC_ECCV20/">EPIC@ECCV2020</a><br>
Area Chair: ICCV 2023, WACV 2023
<br>
Associate Editor: CVIU since 2023
<br>
Reviewer: CVPR since 2020, ICCV since 2019, ECCV since 2020, TPAMI 2020-2022, IJCV 2021-2022, NeurIPS 2022, ACCV 2020, WACV 2020-2021, AAAI 2020
<br>
Outstading Reviewer: CVPR 2023, ECCV 2022, ICCV 2021, CVPR 2021, ECCV 2020, ACCV 2020

<br>
<h1 id="teaching" style="padding-top: 20px">Teaching</h1>
<hr />
<br>
Unit Coordinator: Leren en Beslissen (Learning and Decision Making), 2022 (BSc AI, Y2)
<br>
Guest Lecture: Computer Vision 2, 2021 

      </div>
    </div>

    <footer class="site-footer">



</footer>

  </body>

</html>
